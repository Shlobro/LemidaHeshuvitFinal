{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Load the data as a pandas dataframe\n",
    "### 2. create a mapping of the personality types\n",
    "### 3. replace text values with numerical values\n",
    "### 4. get rid of the \"Response ID\" column (duh)\n",
    "### 5. convert to a pandas array"
   ],
   "id": "83c6cb2cfdecbfcf"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-22T18:10:47.099788Z",
     "start_time": "2025-06-22T18:10:46.948323Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV\n",
    "df = pd.read_csv('16P.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Step 2: Define your mapping dictionary\n",
    "mbti_mapping = {\n",
    "    'ESTJ': 0, 'ENTJ': 1, 'ESFJ': 2, 'ENFJ': 3,\n",
    "    'ISTJ': 4, 'ISFJ': 5, 'INTJ': 6, 'INFJ': 7,\n",
    "    'ESTP': 8, 'ESFP': 9, 'ENTP': 10, 'ENFP': 11,\n",
    "    'ISTP': 12, 'ISFP': 13, 'INTP': 14, 'INFP': 15\n",
    "}\n",
    "\n",
    "# Step 3: Apply mapping to the \"Personality\" column\n",
    "df['Personality'] = df['Personality'].map(mbti_mapping)\n",
    "\n",
    "# Step 4: Drop non-numerical identifier columns if needed (e.g., \"Response Id\")\n",
    "df = df.drop(columns=['Response Id'])\n",
    "\n",
    "# Step 5: Convert to NumPy 2D array\n",
    "data_array = df.to_numpy()\n",
    "\n",
    "# Now data_array is a NumPy 2D array ready for ML usage\n",
    "print(data_array.shape)\n",
    "\n",
    "data_array"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 61)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  0, 11],\n",
       "       [ 0,  0, -2, ..., -1,  3, 13],\n",
       "       [ 0,  0,  2, ...,  2,  1,  7],\n",
       "       ...,\n",
       "       [ 0,  0,  1, ...,  0, -1, 12],\n",
       "       [ 0,  0,  1, ...,  1,  0,  4],\n",
       "       [ 0,  0,  2, ...,  0, -1,  7]], shape=(59999, 61))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### -Split the array into X and y columns\n",
    "### -Split the data into Train and Test\n"
   ],
   "id": "78ea257d68d5cbb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T18:10:47.270062Z",
     "start_time": "2025-06-22T18:10:47.208684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your NumPy array is called data_array\n",
    "# Features = all columns except last, Labels = last column\n",
    "X = data_array[:, :-1]  # features\n",
    "y = data_array[:, -1]   # labels\n",
    "\n",
    "# Split into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# just to make sure the data is split evenly\n",
    "# unique, counts = np.unique(y_train, return_counts=True)\n",
    "# print(\"\\nDistribution of unique values:\")\n",
    "# for label, count in zip(unique, counts):\n",
    "#     print(f\"{label}: {count}\")\n"
   ],
   "id": "2208ed324501df83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (47999, 60)\n",
      "y_train shape: (47999,)\n",
      "X_test shape: (12000, 60)\n",
      "y_test shape: (12000,)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Entropy function",
   "id": "d8673c67d1560545"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T14:47:53.907041Z",
     "start_time": "2025-07-03T14:47:53.897173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def entropy(y):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    probs = counts / len(y)\n",
    "    return -np.sum(probs * np.log2(probs))"
   ],
   "id": "60fa156e7e69d2f5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gini Function",
   "id": "81dc381c8177e80a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# implement later , this function will replace Entropy",
   "id": "40245263e01bf4f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Gain function\n",
    "\n",
    "### Information Gain\n",
    "### Information Gain tells us how much entropy decreases after a split:\n",
    "\n",
    "### [ IG(S, A) = H(S) - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|} H(S_v) ]\n",
    "\n",
    "#Where:\n",
    "\n",
    "##### ( A ): the attribute to split on\n",
    "##### ( S_v ): subset of data where attribute ( A = v )"
   ],
   "id": "4ce02068343e46d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T15:11:17.041233Z",
     "start_time": "2025-07-03T15:11:17.034886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def Gain(parent_entropy, R1, R2):\n",
    "    total_Len = len(R1) + len(R2)\n",
    "\n",
    "    R1_wieght = len(R1) / total_Len #  R1 percentage out of R\n",
    "    R2_wieght = len(R2) / total_Len\n",
    "\n",
    "    entropy_R1 = entropy(R1)\n",
    "    entropy_R2 = entropy(R2)\n",
    "\n",
    "    weighted_entropy = R1_wieght * entropy_R1 + R2_wieght * entropy_R2\n",
    "\n",
    "    return parent_entropy - weighted_entropy\n"
   ],
   "id": "fcfa36feb52939f0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## Gain Usage/Example",
   "id": "5bc1eabc79b58ba1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### split data to R1 and R2",
   "id": "964c39486e3349a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def split(feature: np.ndarray, threshold: float, Y: np.ndarray):\n",
    "    \"\"\"\n",
    "    Splits the label array Y into two groups based on feature ≤ threshold.\n",
    "\n",
    "    Parameters:\n",
    "        feature (np.ndarray): Numeric values (same length as Y)\n",
    "        threshold (float): Threshold to split on\n",
    "        Y (np.ndarray): Corresponding labels\n",
    "\n",
    "    Returns:\n",
    "        r1 (np.ndarray): Labels where feature ≤ threshold\n",
    "        r2 (np.ndarray): Labels where feature > threshold\n",
    "    \"\"\"\n",
    "    mask = feature <= threshold\n",
    "    r1 = Y[mask]\n",
    "    r2 = Y[~mask]\n",
    "    return r1, r2"
   ],
   "id": "d6da47dd91968e04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calculate all Gains",
   "id": "dbc983fcf4da4a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def best_split(X, y):\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    best_feature = None\n",
    "    best_gain = 0\n",
    "    best_threshold = None\n",
    "    parent_entropy = entropy(y)\n",
    "\n",
    "    for feature in range(n_features):\n",
    "        # Sort feature values along with y\n",
    "        sorted_indices = X[:, feature].argsort()\n",
    "        X_sorted = X[sorted_indices]\n",
    "        y_sorted = y[sorted_indices]\n",
    "\n",
    "        # Loop through all adjacent pairs to find candidate thresholds\n",
    "        for i in range(n_samples - 1):\n",
    "            curr_val = X_sorted[i, feature]\n",
    "            next_val = X_sorted[i + 1, feature]\n",
    "\n",
    "            if curr_val == next_val:\n",
    "                continue  # Skip duplicate values\n",
    "\n",
    "            threshold = (curr_val + next_val) / 2\n",
    "\n",
    "            # Split labels based on threshold\n",
    "            left_mask = X[:, feature] <= threshold\n",
    "            right_mask = X[:, feature] > threshold\n",
    "            y_left = y[left_mask]\n",
    "            y_right = y[right_mask]\n",
    "\n",
    "            if len(y_left) == 0 or len(y_right) == 0:\n",
    "                continue  # Skip invalid splits\n",
    "\n",
    "            gain = Gain(parent_entropy, y_right, y_left)\n",
    "\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = feature\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_feature, best_threshold\n"
   ],
   "id": "3988794cb05f9953"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
